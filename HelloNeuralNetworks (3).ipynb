{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HelloNeuralNetworks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExRBdSDTk_qh"
      },
      "source": [
        "# Welcome to Hello Neural Networks\n",
        "In this project I implement a multilayer perceptron on the MNIST dataset, without the use of any tensorflow or pytorch to build the models, or following along some tutorial resource.\n",
        "\n",
        ">Note: Almost all of the math implemented in this project has been learnt with the help of the Andrew NG course on deep learning specialization. I highly recommend you to check it out on coursera.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX2ov4YjGFG9"
      },
      "source": [
        "''' This is a basic neural network developed from scratch, which can recognize handwritten digits from the MNIST dataset'''\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import time\n",
        "\n",
        "ohe = preprocessing.OneHotEncoder()\n",
        "(X_train,Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nzMjm1efRvj"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWd9baPFnGS6"
      },
      "source": [
        "# Basic Structure and Training of the Model\n",
        "Throughout the model a dictionary \"paras\" is passed around all functions which contains all the parameters of the model.\n",
        "The model function runs the training of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYOJuADbGqba",
        "outputId": "9dc3044a-a964-4a97-b2a1-def2b74c46ad"
      },
      "source": [
        "(X_train,Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()\n",
        "n0 = np.shape(X_train[0])[0]*np.shape(X_train[0])[1]\n",
        "n1 = 16\n",
        "n2 = 10\n",
        "\n",
        "\n",
        "X_train_final = X_train.reshape(X_train.shape[0],-1).T\n",
        "\n",
        "X_test_final = X_test.reshape(X_test.shape[0],-1).T\n",
        "Y_train_temp = Y_train.reshape(-1, 1)\n",
        "Y_test_temp = Y_test.reshape(-1, 1)\n",
        "# Y_train_temp = Y_train.reshape(1,Y_train.shape[0])\n",
        "# Y_test_temp = Y_test.reshape(1,Y_test.shape[0])\n",
        "ohe.fit(Y_train_temp)\n",
        "Y_train_final = ohe.transform(Y_train_temp).toarray().T\n",
        "# print(Y_train_final[:,335])\n",
        "# print(Y_train_temp[335])\n",
        "\n",
        "# Fit and transform testing data\n",
        "ohe.fit(Y_test_temp)\n",
        "Y_test_final = ohe.transform(Y_test_temp).toarray().T\n",
        "# print(Y_train_final.shape)\n",
        "# print(Y_train_final[0][0])\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# Y_train_final= to_categorical(Y_train_final).reshape(10,Y_train.shape[0])\n",
        "# print(Y_train_final[:, 1])\n",
        "# print(Y_train_final.shape)\n",
        "\n",
        "def prep(n2 = 10,n1 = 16, n0 = np.shape(X_train[0])[0]*np.shape(X_train[0])[1]):\n",
        "  W1 = np.random.randn(n1,n0)*0.1\n",
        "  B1 = np.zeros((n1,1))\n",
        "  W2 = np.random.randn(n2,n1)*0.1\n",
        "  B2 = np.zeros((n2,1))\n",
        "  paras = {\n",
        "      \"W1\" : W1,\n",
        "      \"W2\" : W2,\n",
        "      \"B1\" : B1,\n",
        "      \"B2\" : B2,\n",
        "      \"m\" : X_train.shape[0]\n",
        "  }\n",
        "  return paras\n",
        "\n",
        "\n",
        "def forward(paras, X = X_train_final):\n",
        "  W1 = paras[\"W1\"]\n",
        "  W2 = paras[\"W2\"]\n",
        "  B1 = paras[\"B1\"]\n",
        "  B2 = paras[\"B2\"]\n",
        "  Z1 = np.dot(W1,X) + B1\n",
        "  \n",
        "  A1 = np.tanh(Z1)\n",
        "  \n",
        "  Z2 = np.dot(W2,A1) +B2\n",
        "  \n",
        "  A2 = 1/(1+np.exp(-Z2))\n",
        "  \n",
        "  \n",
        "  \n",
        "  paras[\"Z1\"] =Z1\n",
        "  paras[\"Z2\"] =Z2\n",
        "  paras[\"A1\"] =A1\n",
        "  paras[\"A2\"] =A2\n",
        "  return paras\n",
        "  \n",
        "\n",
        "def cost(paras,Y = Y_train_final):\n",
        "  #check if this is correct\n",
        "  A2 = paras[\"A2\"]\n",
        "  m = paras[\"m\"]\n",
        "  # print(\"reached\")\n",
        "  # # cost = -(1/m)*(np.dot(Y.T,np.log(A2))+np.dot((1-Y).T,np.log(1-A2)))\n",
        "  # print(cost)\n",
        "  # cost = float(np.squeeze(cost))\n",
        "  # logprobs = np.multiply(np.log(A2),Y)+np.multiply(np.log(1-A2),1-Y)\n",
        "  logprobs = np.multiply(Y,np.log(A2))+np.multiply(1-Y,np.log(1-A2))\n",
        "  cost = -(1/m)*np.sum(logprobs)\n",
        "    ### END CODE HERE ###\n",
        "  \n",
        "  cost = float(np.squeeze(cost))\n",
        "  paras[\"cost\"] = cost\n",
        "  return paras\n",
        "\n",
        "def backward(paras,X = X_train_final,Y = Y_train_final):\n",
        "  A2 = paras[\"A2\"]\n",
        "  A1 = paras[\"A1\"]\n",
        "  W2 = paras[\"W2\"]\n",
        "  W1 = paras[\"W1\"]\n",
        "  m = paras[\"m\"]\n",
        "  dZ2 = np.subtract(A2,Y)\n",
        "  \n",
        "  dW2 = (1/m)*(np.dot(dZ2,A1.T))\n",
        "  dB2 = (1/m)*(np.sum(dZ2,axis = 1,keepdims = True))\n",
        "  # dZ1 = np.multiply(np.dot(W2.T,dZ2),1-np.power(A1,2))\n",
        "  \n",
        "\n",
        "  \n",
        "  dZ1 = np.dot(W2.T, dZ2)*(1 - np.power(A1, 2))\n",
        "  dW1 = (1/m)*(np.dot(dZ1,X.T))\n",
        "  dB1 = (1/m)*(np.sum(dZ1,axis = 1,keepdims = True))\n",
        "  paras[\"dW1\"] = dW1\n",
        "  paras[\"dW2\"] = dW2\n",
        "  paras[\"dB1\"] = dB1\n",
        "  paras[\"dB2\"] = dB2\n",
        "  \n",
        "  return paras\n",
        "\n",
        "def update(paras):\n",
        "  lr = 0.06\n",
        "  dW1 = paras[\"dW1\"]\n",
        "  dW2 = paras[\"dW2\"]\n",
        "  dB1 = paras[\"dB1\"]\n",
        "  dB2 = paras[\"dB2\"]\n",
        "  W1 = paras[\"W1\"]\n",
        "  W2 = paras[\"W2\"]\n",
        "  B1 = paras[\"B1\"]\n",
        "  B2 = paras[\"B2\"]\n",
        "  W1 = W1 - lr*dW1\n",
        "  W2 = W2 -lr*dW2\n",
        "  B1 = B1 -lr*dB1\n",
        "  B2 = B2 - lr*dB2\n",
        "  paras[\"W1\"] =W1\n",
        "  paras[\"W2\"] =W2\n",
        "  paras[\"B1\"] =B1\n",
        "  paras[\"B2\"] =B2\n",
        "  \n",
        "  return paras\n",
        "def model(n2 = 10,n1 = 16, n0 = np.shape(X_train[0])[0]*np.shape(X_train[0])[1],iter = 5000):\n",
        "  paras = prep()\n",
        "  start = time.time()\n",
        "  for i in range(iter):\n",
        "    paras = forward(paras)\n",
        "    paras = cost(paras)\n",
        "    c = paras[\"cost\"]\n",
        "    paras = backward(paras)\n",
        "    paras = update(paras)\n",
        "   \n",
        "    if  i % 500 == 0:\n",
        "      \n",
        "      print(\"Cost after iteration %i: %f\" %(i, c))\n",
        "  end = time.time()\n",
        "  print(f\"Learning time of the program is {end - start}\")\n",
        "  return paras\n",
        "\n",
        "trained_vals = model()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 0: 7.115943\n",
            "Cost after iteration 500: 1.611916\n",
            "Cost after iteration 1000: 1.293188\n",
            "Cost after iteration 1500: 1.162978\n",
            "Cost after iteration 2000: 1.032402\n",
            "Cost after iteration 2500: 0.973768\n",
            "Cost after iteration 3000: 0.934175\n",
            "Cost after iteration 3500: 0.901273\n",
            "Cost after iteration 4000: 0.880159\n",
            "Cost after iteration 4500: 0.863200\n",
            "Learning time of the program is 2387.7228178977966\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJxopzFQuNdt"
      },
      "source": [
        "# Testing and Saving Trained Model\n",
        "The predict function tests the model and gives the accuracy on the testing dataset.\n",
        "\n",
        "As I have not used a model class in the script, I save the data by saving the trained parameters in a csv file loaded onto the mounted google drive.\n",
        "\n",
        "The load_paras function automatically loads these csv files back to the model according to the naming convention.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE2dsWivIyMp",
        "outputId": "6630322d-e0f5-4bee-e36d-a35115d3acd1"
      },
      "source": [
        "#0.0001 -- > 53%\n",
        "#0.0009 --> 79%\n",
        "#0.09 --> 87.68% (TOO LARGE)\n",
        "#0.03 -- > 84.49% \n",
        "#0.06 --> 89.98% (can be increased)\n",
        "#0.07 -> 87.15%\n",
        "#0.05 --> 88.43%\n",
        "\n",
        "def save_paras(paras,accuracy = 89):\n",
        "  W1 = paras[\"W1\"]\n",
        "  W2 = paras[\"W2\"]\n",
        "  B1 = paras[\"B1\"]\n",
        "  B2 = paras[\"B2\"]\n",
        "  np.savetxt(f'/content/gdrive/MyDrive/NeuralNetworkValues/W1_{accuracy}.csv', W1, delimiter=',')\n",
        "  np.savetxt(f'/content/gdrive/MyDrive/NeuralNetworkValues/W2_{accuracy}.csv', W2, delimiter=',')\n",
        "  np.savetxt(f'/content/gdrive/MyDrive/NeuralNetworkValues/B1_{accuracy}.csv', B1, delimiter=',')\n",
        "  np.savetxt(f'/content/gdrive/MyDrive/NeuralNetworkValues/B2_{accuracy}.csv', B2, delimiter=',')\n",
        "\n",
        "def load_paras(accuracy = 84):\n",
        "  W1 = np.loadtxt(f'/content/gdrive/MyDrive/NeuralNetworkValues/W1_{accuracy}.csv', delimiter=',')\n",
        "  W2 = np.loadtxt(f'/content/gdrive/MyDrive/NeuralNetworkValues/W2_{accuracy}.csv', delimiter=',')\n",
        "  B1 = np.loadtxt(f'/content/gdrive/MyDrive/NeuralNetworkValues/B1_{accuracy}.csv', delimiter=',').reshape(n1,1)\n",
        "  B2 = np.loadtxt(f'/content/gdrive/MyDrive/NeuralNetworkValues/B2_{accuracy}.csv', delimiter=',').reshape(n2,1)\n",
        "  paras = {\n",
        "      \"W1\":W1,\n",
        "      \"W2\":W2,\n",
        "      \"B1\":B1,\n",
        "      \"B2\":B2\n",
        "  }\n",
        "  return paras\n",
        "def predict(paras):\n",
        "  \n",
        "  predicted = forward(paras,X_test_final)\n",
        "  A2 = predicted[\"A2\"]\n",
        "  tests = Y_test_final.shape[1]\n",
        "  print(\"Number of test cases: \", tests)\n",
        "  final = (A2 == A2.max(axis=0)[None,:]).astype(int)\n",
        "  correct = 0\n",
        "  incorrect = []\n",
        "  for i in range(tests):\n",
        "    if(np.array_equal(final[:,i], Y_test_final[:,i])):\n",
        "      correct += 1\n",
        "    else:\n",
        "      incorrect.append(i)\n",
        "  accuracy = correct/tests*100\n",
        "  print(f\"Accuracy is: {accuracy} %\")\n",
        "  print(f\"Incorrect test cases are: \", incorrect)\n",
        "  save_paras(paras,int(accuracy))\n",
        "  return final\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "final = predict(trained_vals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test cases:  10000\n",
            "Accuracy is: 85.86 %\n",
            "Incorrect test cases are:  [8, 18, 33, 38, 62, 63, 66, 72, 73, 80, 104, 111, 118, 119, 125, 132, 149, 150, 151, 193, 195, 214, 217, 221, 233, 241, 244, 245, 247, 257, 259, 268, 274, 282, 313, 318, 320, 336, 340, 341, 344, 349, 352, 353, 359, 362, 366, 376, 381, 389, 391, 421, 435, 445, 448, 457, 460, 464, 465, 468, 478, 479, 495, 497, 498, 502, 505, 507, 511, 514, 515, 527, 528, 530, 531, 543, 551, 552, 553, 565, 569, 571, 578, 591, 593, 595, 597, 606, 610, 618, 619, 627, 628, 638, 658, 659, 667, 674, 684, 689, 691, 692, 710, 717, 720, 730, 737, 740, 787, 791, 795, 800, 804, 810, 817, 829, 839, 844, 857, 866, 874, 877, 882, 884, 898, 900, 906, 919, 924, 938, 939, 944, 947, 950, 956, 959, 965, 969, 975, 982, 992, 993, 994, 1000, 1014, 1023, 1024, 1028, 1032, 1033, 1044, 1045, 1050, 1052, 1062, 1078, 1082, 1089, 1093, 1096, 1101, 1107, 1112, 1114, 1119, 1124, 1153, 1154, 1156, 1157, 1181, 1191, 1192, 1194, 1200, 1202, 1204, 1206, 1208, 1217, 1226, 1228, 1231, 1232, 1234, 1242, 1243, 1247, 1248, 1249, 1251, 1253, 1256, 1260, 1273, 1279, 1282, 1283, 1288, 1289, 1299, 1314, 1315, 1317, 1319, 1325, 1326, 1328, 1337, 1345, 1347, 1352, 1356, 1357, 1364, 1374, 1375, 1378, 1384, 1393, 1402, 1404, 1410, 1411, 1415, 1423, 1429, 1431, 1433, 1435, 1439, 1440, 1444, 1446, 1454, 1462, 1465, 1466, 1476, 1494, 1495, 1500, 1502, 1504, 1522, 1525, 1527, 1530, 1549, 1553, 1554, 1558, 1559, 1568, 1570, 1581, 1594, 1595, 1600, 1604, 1607, 1609, 1614, 1617, 1621, 1626, 1634, 1637, 1638, 1640, 1641, 1644, 1654, 1669, 1670, 1678, 1681, 1691, 1692, 1695, 1696, 1702, 1709, 1712, 1717, 1718, 1721, 1722, 1732, 1737, 1740, 1749, 1750, 1751, 1754, 1755, 1772, 1778, 1782, 1790, 1798, 1800, 1808, 1813, 1819, 1828, 1843, 1850, 1855, 1878, 1882, 1883, 1901, 1913, 1915, 1917, 1918, 1920, 1926, 1927, 1938, 1941, 1952, 1955, 1969, 1970, 1973, 1982, 1987, 2016, 2023, 2024, 2033, 2035, 2040, 2043, 2044, 2050, 2053, 2057, 2067, 2068, 2070, 2098, 2099, 2105, 2106, 2107, 2109, 2115, 2116, 2118, 2125, 2129, 2130, 2131, 2135, 2148, 2149, 2180, 2182, 2183, 2185, 2186, 2189, 2192, 2197, 2208, 2224, 2229, 2237, 2254, 2266, 2271, 2272, 2274, 2282, 2292, 2293, 2294, 2298, 2300, 2305, 2311, 2318, 2320, 2322, 2325, 2326, 2327, 2328, 2329, 2333, 2342, 2348, 2351, 2358, 2369, 2370, 2378, 2380, 2381, 2384, 2387, 2393, 2395, 2404, 2406, 2408, 2414, 2422, 2425, 2433, 2443, 2448, 2449, 2457, 2460, 2497, 2509, 2512, 2516, 2521, 2526, 2534, 2535, 2542, 2548, 2550, 2556, 2559, 2560, 2570, 2573, 2574, 2582, 2589, 2598, 2607, 2609, 2610, 2611, 2616, 2627, 2631, 2635, 2636, 2642, 2648, 2654, 2658, 2659, 2660, 2668, 2670, 2681, 2689, 2695, 2705, 2713, 2720, 2721, 2727, 2728, 2730, 2740, 2743, 2748, 2751, 2758, 2760, 2770, 2776, 2778, 2780, 2801, 2802, 2805, 2810, 2812, 2832, 2834, 2850, 2852, 2854, 2863, 2877, 2894, 2896, 2906, 2907, 2914, 2919, 2925, 2953, 2960, 2970, 2971, 2972, 2977, 2995, 3005, 3011, 3015, 3021, 3029, 3030, 3033, 3042, 3060, 3062, 3073, 3078, 3100, 3102, 3111, 3114, 3115, 3117, 3129, 3130, 3132, 3133, 3139, 3145, 3146, 3149, 3150, 3160, 3171, 3176, 3178, 3183, 3185, 3189, 3205, 3206, 3225, 3240, 3251, 3254, 3263, 3269, 3280, 3283, 3289, 3292, 3295, 3303, 3316, 3322, 3323, 3329, 3330, 3335, 3339, 3347, 3358, 3361, 3369, 3377, 3381, 3399, 3404, 3405, 3408, 3410, 3414, 3422, 3441, 3444, 3447, 3448, 3450, 3460, 3468, 3475, 3476, 3490, 3498, 3503, 3504, 3506, 3511, 3516, 3520, 3525, 3533, 3540, 3547, 3549, 3550, 3558, 3559, 3565, 3567, 3573, 3575, 3597, 3598, 3599, 3604, 3612, 3613, 3615, 3618, 3626, 3629, 3631, 3634, 3636, 3640, 3645, 3662, 3674, 3681, 3685, 3687, 3691, 3710, 3716, 3718, 3726, 3727, 3730, 3742, 3749, 3751, 3754, 3755, 3756, 3767, 3769, 3776, 3778, 3780, 3799, 3801, 3806, 3808, 3811, 3817, 3818, 3821, 3831, 3832, 3833, 3834, 3835, 3836, 3838, 3846, 3848, 3853, 3856, 3862, 3864, 3869, 3871, 3876, 3884, 3893, 3895, 3897, 3902, 3906, 3909, 3916, 3924, 3926, 3929, 3941, 3943, 3950, 3951, 3952, 3958, 3962, 3970, 3975, 3984, 3985, 3986, 3987, 3994, 3998, 4000, 4013, 4015, 4017, 4027, 4044, 4052, 4054, 4059, 4063, 4065, 4071, 4072, 4075, 4076, 4078, 4086, 4093, 4107, 4141, 4145, 4149, 4151, 4152, 4159, 4163, 4164, 4165, 4174, 4176, 4177, 4188, 4199, 4201, 4205, 4211, 4212, 4224, 4239, 4248, 4255, 4260, 4261, 4265, 4268, 4271, 4284, 4289, 4293, 4297, 4300, 4301, 4302, 4306, 4312, 4313, 4315, 4317, 4321, 4325, 4327, 4330, 4343, 4358, 4359, 4360, 4374, 4391, 4395, 4403, 4405, 4408, 4419, 4425, 4433, 4435, 4439, 4440, 4449, 4451, 4454, 4461, 4463, 4477, 4479, 4482, 4487, 4489, 4497, 4498, 4500, 4515, 4523, 4532, 4536, 4540, 4548, 4552, 4560, 4571, 4573, 4575, 4583, 4594, 4601, 4604, 4605, 4615, 4619, 4633, 4639, 4640, 4656, 4657, 4671, 4673, 4690, 4692, 4696, 4702, 4720, 4722, 4723, 4724, 4731, 4737, 4738, 4739, 4740, 4751, 4755, 4761, 4763, 4785, 4789, 4807, 4808, 4813, 4814, 4820, 4823, 4829, 4833, 4834, 4837, 4838, 4852, 4860, 4861, 4874, 4880, 4886, 4890, 4902, 4915, 4928, 4939, 4941, 4943, 4950, 4952, 4956, 4964, 4966, 4969, 4971, 4978, 4990, 4995, 4998, 5001, 5009, 5015, 5038, 5046, 5049, 5062, 5065, 5067, 5068, 5074, 5078, 5086, 5140, 5141, 5143, 5173, 5201, 5206, 5209, 5210, 5221, 5237, 5246, 5269, 5278, 5288, 5299, 5311, 5331, 5358, 5359, 5360, 5409, 5445, 5450, 5468, 5495, 5522, 5523, 5525, 5528, 5530, 5545, 5547, 5564, 5569, 5572, 5574, 5600, 5603, 5608, 5611, 5617, 5620, 5634, 5635, 5642, 5645, 5649, 5653, 5662, 5663, 5671, 5676, 5677, 5678, 5680, 5683, 5688, 5705, 5709, 5714, 5718, 5731, 5734, 5735, 5749, 5752, 5757, 5771, 5780, 5821, 5841, 5842, 5843, 5851, 5852, 5857, 5858, 5862, 5867, 5868, 5874, 5883, 5887, 5888, 5891, 5910, 5912, 5913, 5914, 5922, 5935, 5936, 5937, 5938, 5945, 5955, 5973, 5974, 5975, 5982, 5987, 6005, 6009, 6023, 6030, 6034, 6035, 6037, 6040, 6045, 6046, 6059, 6065, 6071, 6081, 6091, 6109, 6112, 6124, 6126, 6155, 6157, 6160, 6166, 6168, 6172, 6173, 6194, 6238, 6305, 6314, 6324, 6333, 6341, 6347, 6385, 6386, 6392, 6400, 6402, 6405, 6421, 6425, 6426, 6428, 6432, 6458, 6480, 6504, 6505, 6507, 6542, 6552, 6554, 6555, 6557, 6559, 6560, 6564, 6565, 6568, 6569, 6571, 6572, 6573, 6574, 6575, 6576, 6577, 6580, 6582, 6587, 6593, 6597, 6598, 6603, 6610, 6614, 6619, 6624, 6627, 6632, 6636, 6641, 6643, 6645, 6651, 6657, 6662, 6677, 6681, 6698, 6706, 6721, 6730, 6740, 6744, 6746, 6755, 6768, 6769, 6772, 6775, 6776, 6783, 6784, 6785, 6787, 6793, 6796, 6803, 6806, 6807, 6813, 6817, 6818, 6836, 6854, 6866, 6867, 6870, 6872, 6885, 6886, 6894, 6895, 6903, 6905, 6906, 6914, 6919, 6964, 6981, 6997, 7002, 7018, 7029, 7035, 7049, 7094, 7102, 7107, 7121, 7130, 7178, 7195, 7198, 7200, 7208, 7220, 7233, 7241, 7259, 7265, 7304, 7309, 7320, 7337, 7363, 7370, 7372, 7393, 7397, 7402, 7408, 7413, 7423, 7426, 7432, 7433, 7434, 7451, 7454, 7456, 7459, 7465, 7472, 7473, 7481, 7487, 7492, 7494, 7495, 7498, 7505, 7511, 7514, 7524, 7530, 7539, 7541, 7542, 7545, 7552, 7558, 7559, 7565, 7569, 7574, 7579, 7595, 7603, 7619, 7635, 7637, 7639, 7641, 7643, 7651, 7671, 7672, 7673, 7687, 7713, 7735, 7736, 7752, 7756, 7777, 7779, 7797, 7808, 7809, 7812, 7813, 7821, 7823, 7826, 7842, 7845, 7847, 7849, 7850, 7853, 7858, 7859, 7862, 7870, 7875, 7876, 7886, 7888, 7893, 7899, 7905, 7906, 7918, 7921, 7928, 7945, 7946, 7952, 7979, 7991, 7999, 8002, 8006, 8016, 8020, 8028, 8044, 8050, 8059, 8062, 8066, 8069, 8081, 8091, 8094, 8095, 8098, 8104, 8183, 8212, 8246, 8253, 8254, 8262, 8263, 8272, 8273, 8277, 8286, 8290, 8293, 8294, 8296, 8304, 8308, 8311, 8318, 8321, 8332, 8337, 8339, 8362, 8383, 8408, 8416, 8419, 8426, 8456, 8457, 8477, 8486, 8504, 8513, 8520, 8522, 8523, 8527, 8530, 8531, 8547, 8584, 8598, 8602, 8607, 8639, 8679, 8781, 8882, 8952, 9007, 9008, 9009, 9010, 9012, 9013, 9014, 9015, 9019, 9024, 9031, 9036, 9045, 9063, 9071, 9079, 9103, 9153, 9158, 9170, 9182, 9209, 9210, 9214, 9259, 9268, 9280, 9316, 9375, 9398, 9400, 9421, 9422, 9425, 9427, 9428, 9433, 9446, 9456, 9463, 9465, 9468, 9479, 9482, 9506, 9508, 9513, 9522, 9530, 9539, 9552, 9554, 9558, 9571, 9587, 9595, 9610, 9624, 9634, 9664, 9666, 9672, 9700, 9706, 9712, 9716, 9719, 9726, 9728, 9729, 9732, 9733, 9734, 9738, 9740, 9744, 9745, 9749, 9752, 9755, 9762, 9764, 9768, 9770, 9777, 9779, 9808, 9826, 9829, 9831, 9835, 9839, 9847, 9856, 9858, 9867, 9873, 9877, 9879, 9883, 9888, 9889, 9901, 9904, 9905, 9910, 9916, 9925, 9937, 9940, 9941, 9943, 9944, 9951, 9959, 9970, 9975, 9980, 9982, 9985, 9986, 9991]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QTEZivKu-kK"
      },
      "source": [
        "The rest of the code is just testing and playing around :)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjaNwsPdaYOF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "3c33db32-12de-4579-fe8b-40aac833da27"
      },
      "source": [
        "check = 66\n",
        "print(final[:,check])\n",
        "print(Y_test_final[:,check])\n",
        "plt.imshow(X_test[check])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 1 0 0 0 0 0 0 0]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa0ed08a9d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RekeF4vVL67o"
      },
      "source": [
        "save_paras(trained_vals)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo0Dqk6rsFAN"
      },
      "source": [
        "loaded = load_paras(89)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XHoFTb3Lw_6",
        "outputId": "2013e5b6-e67a-44a0-e3f7-258fe1175e53"
      },
      "source": [
        "\n",
        "final = predict(loaded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test cases:  10000\n",
            "Accuracy is: 89.98 %\n",
            "Incorrect test cases are:  [8, 15, 33, 38, 46, 62, 66, 77, 108, 111, 119, 124, 126, 149, 151, 152, 172, 185, 217, 219, 233, 241, 245, 247, 300, 307, 313, 320, 321, 324, 340, 344, 349, 352, 362, 363, 381, 391, 403, 412, 421, 435, 444, 448, 449, 468, 469, 478, 479, 490, 502, 507, 511, 514, 515, 516, 528, 531, 543, 551, 565, 578, 582, 591, 597, 610, 613, 619, 624, 628, 629, 642, 658, 659, 684, 691, 707, 714, 717, 720, 728, 740, 741, 791, 795, 804, 810, 829, 839, 857, 874, 877, 881, 882, 890, 898, 924, 930, 938, 939, 947, 950, 951, 956, 958, 965, 970, 982, 994, 999, 1003, 1012, 1014, 1032, 1033, 1039, 1073, 1079, 1082, 1089, 1093, 1096, 1107, 1112, 1114, 1119, 1156, 1169, 1170, 1178, 1191, 1192, 1194, 1202, 1204, 1206, 1217, 1224, 1226, 1232, 1233, 1234, 1242, 1247, 1248, 1251, 1252, 1256, 1260, 1269, 1272, 1283, 1289, 1308, 1310, 1319, 1320, 1326, 1328, 1331, 1337, 1345, 1364, 1370, 1375, 1378, 1391, 1393, 1404, 1410, 1411, 1413, 1415, 1422, 1433, 1444, 1465, 1467, 1469, 1494, 1500, 1522, 1525, 1527, 1530, 1549, 1553, 1559, 1568, 1569, 1575, 1581, 1587, 1609, 1611, 1621, 1634, 1637, 1640, 1641, 1644, 1660, 1663, 1669, 1678, 1681, 1696, 1709, 1716, 1717, 1718, 1722, 1727, 1732, 1737, 1748, 1754, 1765, 1772, 1786, 1790, 1800, 1808, 1818, 1823, 1828, 1839, 1850, 1855, 1857, 1878, 1901, 1911, 1917, 1930, 1938, 1952, 1954, 1955, 1956, 1969, 1970, 1973, 1982, 1984, 2001, 2009, 2016, 2024, 2029, 2033, 2035, 2043, 2044, 2053, 2057, 2063, 2067, 2070, 2073, 2093, 2098, 2109, 2113, 2114, 2129, 2130, 2134, 2135, 2138, 2145, 2148, 2161, 2182, 2186, 2189, 2192, 2198, 2214, 2224, 2225, 2237, 2266, 2272, 2292, 2293, 2299, 2339, 2350, 2358, 2361, 2369, 2371, 2378, 2380, 2387, 2393, 2396, 2400, 2404, 2406, 2414, 2422, 2425, 2429, 2450, 2460, 2462, 2485, 2488, 2512, 2513, 2526, 2528, 2535, 2545, 2546, 2548, 2556, 2559, 2560, 2573, 2574, 2578, 2586, 2589, 2598, 2604, 2607, 2609, 2610, 2616, 2631, 2635, 2648, 2651, 2654, 2668, 2670, 2681, 2695, 2698, 2705, 2721, 2731, 2743, 2748, 2756, 2770, 2771, 2778, 2780, 2791, 2794, 2797, 2801, 2802, 2812, 2832, 2850, 2863, 2866, 2869, 2894, 2896, 2905, 2906, 2907, 2919, 2925, 2926, 2927, 2945, 2953, 2954, 2976, 2979, 2995, 3005, 3030, 3060, 3062, 3065, 3066, 3069, 3073, 3095, 3100, 3114, 3115, 3117, 3132, 3136, 3145, 3160, 3166, 3183, 3189, 3205, 3206, 3216, 3218, 3219, 3225, 3240, 3245, 3261, 3269, 3275, 3280, 3297, 3319, 3323, 3329, 3333, 3336, 3347, 3351, 3361, 3369, 3383, 3384, 3414, 3422, 3436, 3441, 3447, 3450, 3468, 3475, 3490, 3503, 3504, 3506, 3516, 3520, 3525, 3533, 3549, 3552, 3558, 3559, 3565, 3567, 3573, 3575, 3590, 3597, 3598, 3600, 3604, 3623, 3626, 3629, 3636, 3674, 3681, 3685, 3687, 3688, 3718, 3730, 3749, 3751, 3756, 3763, 3767, 3776, 3778, 3780, 3785, 3794, 3796, 3798, 3806, 3808, 3811, 3817, 3818, 3821, 3835, 3836, 3838, 3839, 3846, 3848, 3853, 3855, 3862, 3869, 3871, 3876, 3893, 3902, 3906, 3912, 3926, 3929, 3936, 3941, 3943, 3946, 3968, 3970, 3976, 3984, 3985, 3986, 3988, 3994, 4007, 4013, 4052, 4059, 4063, 4065, 4071, 4072, 4075, 4076, 4078, 4093, 4131, 4152, 4154, 4156, 4163, 4165, 4173, 4176, 4199, 4201, 4205, 4212, 4224, 4228, 4230, 4238, 4248, 4250, 4254, 4256, 4259, 4261, 4271, 4272, 4284, 4289, 4293, 4300, 4302, 4306, 4317, 4330, 4344, 4355, 4356, 4369, 4374, 4380, 4405, 4411, 4419, 4422, 4423, 4425, 4426, 4427, 4433, 4435, 4440, 4444, 4445, 4449, 4451, 4455, 4461, 4463, 4487, 4497, 4498, 4500, 4504, 4505, 4521, 4523, 4540, 4548, 4571, 4575, 4583, 4601, 4615, 4634, 4657, 4659, 4662, 4690, 4692, 4696, 4698, 4699, 4721, 4731, 4735, 4736, 4739, 4740, 4751, 4761, 4782, 4807, 4814, 4823, 4833, 4837, 4863, 4874, 4876, 4882, 4886, 4888, 4890, 4896, 4910, 4915, 4918, 4942, 4950, 4956, 4966, 4990, 5006, 5035, 5038, 5046, 5054, 5065, 5067, 5068, 5078, 5086, 5088, 5100, 5140, 5141, 5143, 5155, 5165, 5210, 5217, 5243, 5244, 5246, 5251, 5278, 5311, 5331, 5409, 5419, 5523, 5562, 5593, 5608, 5613, 5620, 5623, 5634, 5639, 5642, 5662, 5677, 5720, 5726, 5734, 5749, 5754, 5801, 5824, 5835, 5842, 5852, 5858, 5862, 5867, 5874, 5887, 5888, 5891, 5910, 5912, 5913, 5922, 5937, 5938, 5955, 5957, 5972, 5982, 5985, 5997, 6011, 6024, 6035, 6042, 6043, 6056, 6059, 6065, 6071, 6081, 6091, 6093, 6095, 6109, 6111, 6112, 6124, 6126, 6157, 6165, 6166, 6168, 6172, 6173, 6347, 6370, 6385, 6386, 6390, 6391, 6392, 6400, 6421, 6425, 6426, 6455, 6480, 6505, 6517, 6530, 6542, 6544, 6552, 6555, 6558, 6560, 6565, 6566, 6568, 6571, 6572, 6574, 6575, 6576, 6577, 6592, 6597, 6598, 6603, 6610, 6621, 6625, 6632, 6641, 6642, 6645, 6651, 6657, 6662, 6694, 6721, 6728, 6740, 6744, 6746, 6755, 6768, 6775, 6783, 6784, 6785, 6793, 6796, 6817, 6827, 6847, 6872, 6883, 6895, 6906, 6909, 6914, 6919, 6926, 6981, 7002, 7049, 7081, 7094, 7107, 7121, 7130, 7178, 7195, 7210, 7216, 7220, 7233, 7241, 7258, 7304, 7338, 7350, 7372, 7403, 7426, 7432, 7434, 7446, 7451, 7459, 7473, 7483, 7487, 7491, 7492, 7494, 7498, 7499, 7505, 7514, 7521, 7531, 7539, 7541, 7542, 7580, 7637, 7713, 7724, 7779, 7797, 7800, 7808, 7809, 7812, 7821, 7822, 7826, 7842, 7847, 7849, 7850, 7857, 7858, 7859, 7870, 7886, 7888, 7899, 7900, 7905, 7917, 7918, 7928, 7945, 7946, 8020, 8025, 8050, 8062, 8066, 8091, 8094, 8095, 8128, 8196, 8212, 8254, 8273, 8278, 8279, 8283, 8286, 8288, 8318, 8337, 8339, 8362, 8383, 8406, 8408, 8414, 8416, 8453, 8487, 8493, 8507, 8520, 8521, 8522, 8637, 8643, 8653, 8728, 8863, 8952, 9009, 9010, 9013, 9015, 9016, 9019, 9024, 9031, 9036, 9038, 9045, 9046, 9062, 9085, 9103, 9119, 9128, 9141, 9158, 9168, 9182, 9202, 9209, 9210, 9234, 9280, 9421, 9427, 9446, 9456, 9465, 9482, 9517, 9530, 9535, 9554, 9560, 9587, 9595, 9612, 9634, 9642, 9643, 9653, 9664, 9666, 9679, 9692, 9698, 9700, 9716, 9726, 9728, 9729, 9732, 9738, 9744, 9745, 9749, 9751, 9752, 9754, 9764, 9768, 9770, 9777, 9779, 9780, 9792, 9808, 9811, 9832, 9839, 9847, 9853, 9855, 9858, 9867, 9873, 9874, 9883, 9888, 9893, 9904, 9905, 9910, 9916, 9921, 9936, 9941, 9944, 9947, 9970, 9982]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kLZZ1jmLztA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "94068a13-e8a3-4ebb-d8dc-0adbc49ab504"
      },
      "source": [
        "check = 108\n",
        "print(final[:,check])\n",
        "print(Y_test_final[:,check])\n",
        "plt.imshow(X_test[check])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 1 0]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd91f918450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM4tRha2lXJy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}